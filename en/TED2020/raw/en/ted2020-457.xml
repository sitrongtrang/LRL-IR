<?xml version="1.0" encoding="UTF-8"?>

<text>
 <s id="1">I want to start out by asking you to think back to when you were a kid, playing with blocks.</s>
 <s id="2">As you figured out how to reach out and grasp, pick them up and move them around, you were actually learning how to think and solve problems by understanding and manipulating spatial relationships.</s>
 <s id="3">Spatial reasoning is deeply connected to how we understand a lot of the world around us.</s>
 <s id="4">So, as a computer scientist inspired by this utility of our interactions with physical objects -- along with my adviser Pattie, and my collaborator Jeevan Kalanithi -- I started to wonder -- what if when we used a computer, instead of having this one mouse cursor that was a like a digital fingertip moving around a flat desktop, what if we could reach in with both hands and grasp information physically, arranging it the way we wanted?</s>
 <s id="5">This question was so compelling that we decided to explore the answer, by building Siftables.</s>
 <s id="6">In a nutshell, a Siftable is an interactive computer the size of a cookie.</s>
 <s id="7">They're able to be moved around by hand, they can sense each other, they can sense their motion, and they have a screen and a wireless radio.</s>
 <s id="8">Most importantly, they're physical, so like the blocks, you can move them just by reaching out and grasping.</s>
 <s id="9">And Siftables are an example of a new ecosystem of tools for manipulating digital information.</s>
 <s id="10">And as these tools become more physical, more aware of their motion, aware of each other, and aware of the nuance of how we move them, we can start to explore some new and fun interaction styles.</s>
 <s id="11">So, I'm going to start with some simple examples.</s>
 <s id="12">This Siftable is configured to show video, and if I tilt it in one direction, it'll roll the video this way; if I tilt it the other way it rolls it backwards.</s>
 <s id="13">And these interactive portraits are aware of each other.</s>
 <s id="14">So if I put them next to each other, they get interested.</s>
 <s id="15">If they get surrounded, they notice that too, they might get a little flustered.</s>
 <s id="16">And they can also sense their motion and tilt.</s>
 <s id="17">One of the interesting implications on interaction, we started to realize, was that we could use everyday gestures on data, like pouring a color the way we might pour a liquid.</s>
 <s id="18">So in this case, we've got three Siftables configured to be paint buckets and I can use them to pour color into that central one, where they get mixed.</s>
 <s id="19">If we overshoot, we can pour a little bit back.</s>
 <s id="20">There are also some neat possibilities for education, like language, math and logic games where we want to give people the ability to try things quickly, and view the results immediately.</s>
 <s id="21">So here I'm -- (Applause) This is a Fibonacci sequence that I'm making with a simple equation program.</s>
 <s id="22">Here we have a word game that's kind of like a mash-up between Scrabble and Boggle.</s>
 <s id="23">Basically, in every round you get a randomly assigned letter on each Siftable, and as you try to make words it checks against a dictionary.</s>
 <s id="24">Then, after about 30 seconds, it reshuffles, and you have a new set of letters and new possibilities to try.</s>
 <s id="25">(Applause) Thank you.</s>
 <s id="26">(Applause) So these are some kids that came on a field trip to the Media Lab, and I managed to get them to try it out, and shoot a video.</s>
 <s id="27">They really loved it.</s>
 <s id="28">And, one of the interesting things about this kind of application is that you don't have to give people many instructions.</s>
 <s id="29">All you have to say is, "Make words," and they know exactly what to do.</s>
 <s id="30">So here's another few people trying it out.</s>
 <s id="31">That's our youngest beta tester, down there on the right.</s>
 <s id="32">Turns out, all he wanted to do was to stack the Siftables up.</s>
 <s id="33">So to him, they were just blocks.</s>
 <s id="34">Now, this is an interactive cartoon application.</s>
 <s id="35">And we wanted to build a learning tool for language learners.</s>
 <s id="36">And this is Felix, actually.</s>
 <s id="37">And he can bring new characters into the scene, just by lifting the Siftables off the table that have that character shown on them.</s>
 <s id="38">Here, he's bringing the sun out.</s>
 <s id="39">Video: The sun is rising.</s>
 <s id="40">David Merrill: Now he's brought a tractor into the scene.</s>
 <s id="41">Video: The orange tractor.</s>
 <p id="p42">
  <s id="42.1">Good job!</s>
  <s id="42.2">Yeah!</s>
 </p>
 <s id="43">DM: So by shaking the Siftables and putting them next to each other he can make the characters interact -- Video: Woof!</s>
 <s id="44">DM: inventing his own narrative.</s>
 <s id="45">Video: Hello!</s>
 <s id="46">DM: It's an open-ended story, and he gets to decide how it unfolds.</s>
 <s id="47">Video: Fly away, cat.</s>
 <s id="48">DM: So, the last example I have time to show you today is a music sequencing and live performance tool that we've built recently, in which Siftables act as sounds like lead, bass and drums.</s>
 <s id="49">Each of these has four different variations, you get to choose which one you want to use.</s>
 <s id="50">And you can inject these sounds into a sequence that you can assemble into the pattern that you want.</s>
 <s id="51">And you inject it by just bumping up the sound Siftable against a sequence Siftable.</s>
 <s id="52">There are effects that you can control live, like reverb and filter.</s>
 <s id="53">You attach it to a particular sound and then tilt to adjust it.</s>
 <s id="54">And then, overall effects like tempo and volume that apply to the entire sequence.</s>
 <s id="55">So let's have a look.</s>
 <s id="56">Video: (Music) DM: We'll start by putting a lead into two sequence Siftables, arrange them into a series, extend it, add a little more lead.</s>
 <s id="57">Now I put a bass line in.</s>
 <s id="58">Video: (Music) DM: Now I'll put some percussion in.</s>
 <s id="59">Video: (Music) DM: And now I'll attach the filter to the drums, so I can control the effect live.</s>
 <s id="60">Video: (Music) DM: I can speed up the whole sequence by tilting the tempo one way or the other.</s>
 <s id="61">Video: (Music) DM: And now I'll attach the filter to the bass for some more expression.</s>
 <s id="62">Video: (Music) DM: I can rearrange the sequence while it plays.</s>
 <s id="63">So I don't have to plan it out in advance, but I can improvise, making it longer or shorter as I go.</s>
 <s id="64">And now, finally, I can fade the whole sequence out using the volume Siftable, tilted to the left.</s>
 <s id="65">(Applause) Thank you.</s>
 <s id="66">So, as you can see, my passion is for making new human-computer interfaces that are a better match to the ways our brains and bodies work.</s>
 <s id="67">And today, I had time to show you one point in this new design space, and a few of the possibilities that we're working to bring out of the laboratory.</s>
 <s id="68">So the thought I want to leave you with is that we're on the cusp of this new generation of tools for interacting with digital media that are going to bring information into our world on our terms.</s>
 <s id="69">Thank you very much.</s>
 <s id="70">I look forward to talking with all of you.</s>
 <s id="71">(Applause)</s>
</text>
