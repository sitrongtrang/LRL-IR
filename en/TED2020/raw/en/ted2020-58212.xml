<?xml version="1.0" encoding="UTF-8"?>

<text>
 <s id="1">In 2013, a team of researchers held a math test.</s>
 <s id="2">The exam was administered to over 1,100 American adults, and designed, in part, to test their ability to evaluate sets of data.</s>
 <s id="3">Hidden among these math problems were two almost identical questions.</s>
 <s id="4">Both problems used the same difficult data set, and each had one objectively correct answer.</s>
 <s id="5">The first asked about the correlation between rashes and a new skin cream.</s>
 <s id="6">The second asked about the correlation between crime rates and gun control legislation.</s>
 <s id="7">Participants with strong math skills were much more likely to get the first question correct.</s>
 <s id="8">But despite being mathematically identical, the results for the second question looked totally different.</s>
 <s id="9">Here, math skills weren’t the best predictor of which participants answered correctly.</s>
 <s id="10">Instead, another variable the researchers had been tracking came into play: political identity.</s>
 <s id="11">Participants whose political beliefs aligned with a correct interpretation of the data were far more likely to answer the problem right.</s>
 <s id="12">Even the study’s top mathematicians were 45% more likely to get the second question wrong when the correct answer challenged their political beliefs.</s>
 <s id="13">What is it about politics that inspires this kind of illogical error?</s>
 <s id="14">Can someone’s political identity actually affect their ability to process information?</s>
 <s id="15">The answer lies in a cognitive phenomenon that has become increasingly visible in public life: partisanship.</s>
 <s id="16">While it’s often invoked in the context of politics, partisanship is more broadly defined as a strong preference or bias towards any particular group or idea.</s>
 <s id="17">Our political, ethnic, religious, and national identities are all different forms of partisanship.</s>
 <s id="18">Of course, identifying with social groups is an essential and healthy part of human life.</s>
 <s id="19">Our sense of self is defined not only by who we are as individuals, but also by the groups we belong to.</s>
 <s id="20">As a result, we’re strongly motivated to defend our group identities, protecting both our sense of self and our social communities.</s>
 <s id="21">But this becomes a problem when the group’s beliefs are at odds with reality.</s>
 <s id="22">Imagine watching your favorite sports team commit a serious foul.</s>
 <s id="23">You know that’s against the rules, but your fellow fans think it’s totally acceptable.</s>
 <s id="24">The tension between these two incompatible thoughts is called cognitive dissonance, and most people are driven to resolve this uncomfortable state of limbo.</s>
 <s id="25">You might start to blame the referee, complain that the other team started it, or even convince yourself there was no foul in the first place.</s>
 <s id="26">In a case like this, people are often more motivated to maintain a positive relationship with their group than perceive the world accurately.</s>
 <s id="27">This behavior is especially dangerous in politics.</s>
 <s id="28">On an individual scale, allegiance to a party allows people to create a political identity and support policies they agree with.</s>
 <s id="29">But partisan-based cognitive dissonance can lead people to reject evidence that’s inconsistent with the party line or discredits party leaders.</s>
 <s id="30">And when entire groups of people revise the facts in service of partisan beliefs, it can lead to policies that aren’t grounded in truth or reason.</s>
 <s id="31">This problem isn’t new— political identities have been around for centuries.</s>
 <s id="32">But studies show that partisan polarization has increased dramatically in the last few decades.</s>
 <s id="33">One theory explaining this increase is the trend towards clustering geographically in like-minded communities.</s>
 <s id="34">Another is the growing tendency to rely on partisan news or social media bubbles.</s>
 <s id="35">These often act like echo chambers, delivering news and ideas from people with similar views.</s>
 <s id="36">Fortunately, cognitive scientists have uncovered some strategies for resisting this distortion filter.</s>
 <s id="37">One is to remember that you’re probably more biased than you think.</s>
 <s id="38">So when you encounter new information, make a deliberate effort to push through your initial intuition and evaluate it analytically.</s>
 <s id="39">In your own groups, try to make fact-checking and questioning assumptions a valued part of the culture.</s>
 <s id="40">Warning people that they might have been presented with misinformation can also help.</s>
 <s id="41">And when you’re trying to persuade someone else, affirming their values and framing the issue in their language can help make people more receptive.</s>
 <s id="42">We still have a long way to go before solving the problem of partisanship.</s>
 <s id="43">But hopefully, these tools can help keep us better informed, and capable of making evidence-based decisions about our shared reality.</s>
</text>
