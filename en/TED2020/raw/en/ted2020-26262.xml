<?xml version="1.0" encoding="UTF-8"?>

<text>
 <s id="1">Belle Gibson was a happy young Australian.</s>
 <s id="2">She lived in Perth, and she loved skateboarding.</s>
 <s id="3">But in 2009, Belle learned that she had brain cancer and four months to live.</s>
 <s id="4">Two months of chemo and radiotherapy had no effect.</s>
 <s id="5">But Belle was determined.</s>
 <s id="6">She'd been a fighter her whole life.</s>
 <s id="7">From age six, she had to cook for her brother, who had autism, and her mother, who had multiple sclerosis.</s>
 <s id="8">Her father was out of the picture.</s>
 <s id="9">So Belle fought, with exercise, with meditation and by ditching meat for fruit and vegetables.</s>
 <s id="10">And she made a complete recovery.</s>
 <s id="11">Belle's story went viral.</s>
 <s id="12">It was tweeted, blogged about, shared and reached millions of people.</s>
 <s id="13">It showed the benefits of shunning traditional medicine for diet and exercise.</s>
 <s id="14">In August 2013, Belle launched a healthy eating app, The Whole Pantry, downloaded 200,000 times in the first month.</s>
 <s id="15">But Belle's story was a lie.</s>
 <s id="16">Belle never had cancer.</s>
 <s id="17">People shared her story without ever checking if it was true.</s>
 <s id="18">This is a classic example of confirmation bias.</s>
 <s id="19">We accept a story uncritically if it confirms what we'd like to be true.</s>
 <s id="20">And we reject any story that contradicts it.</s>
 <s id="21">How often do we see this in the stories that we share and we ignore?</s>
 <s id="22">In politics, in business, in health advice.</s>
 <s id="23">The Oxford Dictionary's word of 2016 was "post-truth."</s>
 <s id="24">And the recognition that we now live in a post-truth world has led to a much needed emphasis on checking the facts.</s>
 <s id="25">But the punch line of my talk is that just checking the facts is not enough.</s>
 <s id="26">Even if Belle's story were true, it would be just as irrelevant.</s>
 <s id="27">Why?</s>
 <s id="28">Well, let's look at one of the most fundamental techniques in statistics.</s>
 <s id="29">It's called Bayesian inference.</s>
 <s id="30">And the very simple version is this: We care about "does the data support the theory?"</s>
 <s id="31">Does the data increase our belief that the theory is true?</s>
 <s id="32">But instead, we end up asking, "Is the data consistent with the theory?"</s>
 <s id="33">But being consistent with the theory does not mean that the data supports the theory.</s>
 <s id="34">Why?</s>
 <s id="35">Because of a crucial but forgotten third term -- the data could also be consistent with rival theories.</s>
 <s id="36">But due to confirmation bias, we never consider the rival theories, because we're so protective of our own pet theory.</s>
 <s id="37">Now, let's look at this for Belle's story.</s>
 <s id="38">Well, we care about: Does Belle's story support the theory that diet cures cancer?</s>
 <s id="39">But instead, we end up asking, "Is Belle's story consistent with diet curing cancer?"</s>
 <s id="40">And the answer is yes.</s>
 <s id="41">If diet did cure cancer, we'd see stories like Belle's.</s>
 <s id="42">But even if diet did not cure cancer, we'd still see stories like Belle's.</s>
 <s id="43">A single story in which a patient apparently self-cured just due to being misdiagnosed in the first place.</s>
 <s id="44">Just like, even if smoking was bad for your health, you'd still see one smoker who lived until 100.</s>
 <s id="45">(Laughter) Just like, even if education was good for your income, you'd still see one multimillionaire who didn't go to university.</s>
 <s id="46">(Laughter) So the biggest problem with Belle's story is not that it was false.</s>
 <s id="47">It's that it's only one story.</s>
 <s id="48">There might be thousands of other stories where diet alone failed, but we never hear about them.</s>
 <s id="49">We share the outlier cases because they are new, and therefore they are news.</s>
 <s id="50">We never share the ordinary cases.</s>
 <s id="51">They're too ordinary, they're what normally happens.</s>
 <s id="52">And that's the true 99 percent that we ignore.</s>
 <s id="53">Just like in society, you can't just listen to the one percent, the outliers, and ignore the 99 percent, the ordinary.</s>
 <s id="54">Because that's the second example of confirmation bias.</s>
 <s id="55">We accept a fact as data.</s>
 <s id="56">The biggest problem is not that we live in a post-truth world; it's that we live in a post-data world.</s>
 <s id="57">We prefer a single story to tons of data.</s>
 <s id="58">Now, stories are powerful, they're vivid, they bring it to life.</s>
 <s id="59">They tell you to start every talk with a story.</s>
 <s id="60">I did.</s>
 <s id="61">But a single story is meaningless and misleading unless it's backed up by large-scale data.</s>
 <s id="62">But even if we had large-scale data, that might still not be enough.</s>
 <s id="63">Because it could still be consistent with rival theories.</s>
 <s id="64">Let me explain.</s>
 <s id="65">A classic study by psychologist Peter Wason gives you a set of three numbers and asks you to think of the rule that generated them.</s>
 <s id="66">So if you're given two, four, six, what's the rule?</s>
 <s id="67">Well, most people would think, it's successive even numbers.</s>
 <s id="68">How would you test it?</s>
 <s id="69">Well, you'd propose other sets of successive even numbers: 4, 6, 8 or 12, 14, 16.</s>
 <s id="70">And Peter would say these sets also work.</s>
 <s id="71">But knowing that these sets also work, knowing that perhaps hundreds of sets of successive even numbers also work, tells you nothing.</s>
 <s id="72">Because this is still consistent with rival theories.</s>
 <s id="73">Perhaps the rule is any three even numbers.</s>
 <s id="74">Or any three increasing numbers.</s>
 <s id="75">And that's the third example of confirmation bias: accepting data as evidence, even if it's consistent with rival theories.</s>
 <s id="76">Data is just a collection of facts.</s>
 <s id="77">Evidence is data that supports one theory and rules out others.</s>
 <s id="78">So the best way to support your theory is actually to try to disprove it, to play devil's advocate.</s>
 <s id="79">So test something, like 4, 12, 26.</s>
 <s id="80">If you got a yes to that, that would disprove your theory of successive even numbers.</s>
 <s id="81">Yet this test is powerful, because if you got a no, it would rule out "any three even numbers" and "any three increasing numbers."</s>
 <s id="82">It would rule out the rival theories, but not rule out yours.</s>
 <s id="83">But most people are too afraid of testing the 4, 12, 26, because they don't want to get a yes and prove their pet theory to be wrong.</s>
 <s id="84">Confirmation bias is not only about failing to search for new data, but it's also about misinterpreting data once you receive it.</s>
 <s id="85">And this applies outside the lab to important, real-world problems.</s>
 <s id="86">Indeed, Thomas Edison famously said, "I have not failed, I have found 10,000 ways that won't work."</s>
 <s id="87">Finding out that you're wrong is the only way to find out what's right.</s>
 <s id="88">Say you're a university admissions director and your theory is that only students with good grades from rich families do well.</s>
 <s id="89">So you only let in such students.</s>
 <s id="90">And they do well.</s>
 <s id="91">But that's also consistent with the rival theory.</s>
 <s id="92">Perhaps all students with good grades do well, rich or poor.</s>
 <s id="93">But you never test that theory because you never let in poor students because you don't want to be proven wrong.</s>
 <s id="94">So, what have we learned?</s>
 <s id="95">A story is not fact, because it may not be true.</s>
 <s id="96">A fact is not data, it may not be representative if it's only one data point.</s>
 <s id="97">And data is not evidence -- it may not be supportive if it's consistent with rival theories.</s>
 <s id="98">So, what do you do?</s>
 <s id="99">When you're at the inflection points of life, deciding on a strategy for your business, a parenting technique for your child or a regimen for your health, how do you ensure that you don't have a story but you have evidence?</s>
 <s id="100">Let me give you three tips.</s>
 <s id="101">The first is to actively seek other viewpoints.</s>
 <s id="102">Read and listen to people you flagrantly disagree with.</s>
 <s id="103">Ninety percent of what they say may be wrong, in your view.</s>
 <s id="104">But what if 10 percent is right?</s>
 <s id="105">As Aristotle said, "The mark of an educated man is the ability to entertain a thought without necessarily accepting it."</s>
 <s id="106">Surround yourself with people who challenge you, and create a culture that actively encourages dissent.</s>
 <s id="107">Some banks suffered from groupthink, where staff were too afraid to challenge management's lending decisions, contributing to the financial crisis.</s>
 <s id="108">In a meeting, appoint someone to be devil's advocate against your pet idea.</s>
 <s id="109">And don't just hear another viewpoint -- listen to it, as well.</s>
 <s id="110">As psychologist Stephen Covey said, "Listen with the intent to understand, not the intent to reply."</s>
 <s id="111">A dissenting viewpoint is something to learn from not to argue against.</s>
 <s id="112">Which takes us to the other forgotten terms in Bayesian inference.</s>
 <s id="113">Because data allows you to learn, but learning is only relative to a starting point.</s>
 <s id="114">If you started with complete certainty that your pet theory must be true, then your view won't change -- regardless of what data you see.</s>
 <s id="115">Only if you are truly open to the possibility of being wrong can you ever learn.</s>
 <s id="116">As Leo Tolstoy wrote, "The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already.</s>
 <s id="117">But the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already."</s>
 <s id="118">Tip number two is "listen to experts."</s>
 <s id="119">Now, that's perhaps the most unpopular advice that I could give you.</s>
 <s id="120">(Laughter) British politician Michael Gove famously said that people in this country have had enough of experts.</s>
 <s id="121">A recent poll showed that more people would trust their hairdresser -- (Laughter) or the man on the street than they would leaders of businesses, the health service and even charities.</s>
 <s id="122">So we respect a teeth-whitening formula discovered by a mom, or we listen to an actress's view on vaccination.</s>
 <s id="123">We like people who tell it like it is, who go with their gut, and we call them authentic.</s>
 <s id="124">But gut feel can only get you so far.</s>
 <s id="125">Gut feel would tell you never to give water to a baby with diarrhea, because it would just flow out the other end.</s>
 <s id="126">Expertise tells you otherwise.</s>
 <s id="127">You'd never trust your surgery to the man on the street.</s>
 <s id="128">You'd want an expert who spent years doing surgery and knows the best techniques.</s>
 <s id="129">But that should apply to every major decision.</s>
 <s id="130">Politics, business, health advice require expertise, just like surgery.</s>
 <s id="131">So then, why are experts so mistrusted?</s>
 <s id="132">Well, one reason is they're seen as out of touch.</s>
 <s id="133">A millionaire CEO couldn't possibly speak for the man on the street.</s>
 <s id="134">But true expertise is found on evidence.</s>
 <s id="135">And evidence stands up for the man on the street and against the elites.</s>
 <s id="136">Because evidence forces you to prove it.</s>
 <s id="137">Evidence prevents the elites from imposing their own view without proof.</s>
 <s id="138">A second reason why experts are not trusted is that different experts say different things.</s>
 <s id="139">For every expert who claimed that leaving the EU would be bad for Britain, another expert claimed it would be good.</s>
 <s id="140">Half of these so-called experts will be wrong.</s>
 <s id="141">And I have to admit that most papers written by experts are wrong.</s>
 <s id="142">Or at best, make claims that the evidence doesn't actually support.</s>
 <s id="143">So we can't just take an expert's word for it.</s>
 <s id="144">In November 2016, a study on executive pay hit national headlines.</s>
 <s id="145">Even though none of the newspapers who covered the study had even seen the study.</s>
 <s id="146">It wasn't even out yet.</s>
 <s id="147">They just took the author's word for it, just like with Belle.</s>
 <s id="148">Nor does it mean that we can just handpick any study that happens to support our viewpoint -- that would, again, be confirmation bias.</s>
 <s id="149">Nor does it mean that if seven studies show A and three show B, that A must be true.</s>
 <s id="150">What matters is the quality, and not the quantity of expertise.</s>
 <s id="151">So we should do two things.</s>
 <s id="152">First, we should critically examine the credentials of the authors.</s>
 <s id="153">Just like you'd critically examine the credentials of a potential surgeon.</s>
 <s id="154">Are they truly experts in the matter, or do they have a vested interest?</s>
 <s id="155">Second, we should pay particular attention to papers published in the top academic journals.</s>
 <s id="156">Now, academics are often accused of being detached from the real world.</s>
 <s id="157">But this detachment gives you years to spend on a study.</s>
 <s id="158">To really nail down a result, to rule out those rival theories, and to distinguish correlation from causation.</s>
 <s id="159">And academic journals involve peer review, where a paper is rigorously scrutinized (Laughter) by the world's leading minds.</s>
 <s id="160">The better the journal, the higher the standard.</s>
 <s id="161">The most elite journals reject 95 percent of papers.</s>
 <s id="162">Now, academic evidence is not everything.</s>
 <s id="163">Real-world experience is critical, also.</s>
 <s id="164">And peer review is not perfect, mistakes are made.</s>
 <s id="165">But it's better to go with something checked than something unchecked.</s>
 <s id="166">If we latch onto a study because we like the findings, without considering who it's by or whether it's even been vetted, there is a massive chance that that study is misleading.</s>
 <s id="167">And those of us who claim to be experts should recognize the limitations of our analysis.</s>
 <s id="168">Very rarely is it possible to prove or predict something with certainty, yet it's so tempting to make a sweeping, unqualified statement.</s>
 <s id="169">It's easier to turn into a headline or to be tweeted in 140 characters.</s>
 <s id="170">But even evidence may not be proof.</s>
 <s id="171">It may not be universal, it may not apply in every setting.</s>
 <s id="172">So don't say, "Red wine causes longer life," when the evidence is only that red wine is correlated with longer life.</s>
 <s id="173">And only then in people who exercise as well.</s>
 <s id="174">Tip number three is "pause before sharing anything."</s>
 <s id="175">The Hippocratic oath says, "First, do no harm."</s>
 <s id="176">What we share is potentially contagious, so be very careful about what we spread.</s>
 <s id="177">Our goal should not be to get likes or retweets.</s>
 <s id="178">Otherwise, we only share the consensus; we don't challenge anyone's thinking.</s>
 <s id="179">Otherwise, we only share what sounds good, regardless of whether it's evidence.</s>
 <s id="180">Instead, we should ask the following: If it's a story, is it true?</s>
 <s id="181">If it's true, is it backed up by large-scale evidence?</s>
 <s id="182">If it is, who is it by, what are their credentials?</s>
 <s id="183">Is it published, how rigorous is the journal?</s>
 <s id="184">And ask yourself the million-dollar question: If the same study was written by the same authors with the same credentials but found the opposite results, would you still be willing to believe it and to share it?</s>
 <s id="185">Treating any problem -- a nation's economic problem or an individual's health problem, is difficult.</s>
 <s id="186">So we must ensure that we have the very best evidence to guide us.</s>
 <s id="187">Only if it's true can it be fact.</s>
 <s id="188">Only if it's representative can it be data.</s>
 <s id="189">Only if it's supportive can it be evidence.</s>
 <s id="190">And only with evidence can we move from a post-truth world to a pro-truth world.</s>
 <s id="191">Thank you very much.</s>
 <s id="192">(Applause)</s>
</text>
