<?xml version="1.0" encoding="UTF-8"?>

<text>
 <s id="1">Hello, I'm Joy, a poet of code, on a mission to stop an unseen force that's rising, a force that I called "the coded gaze," my term for algorithmic bias.</s>
 <s id="2">Algorithmic bias, like human bias, results in unfairness.</s>
 <s id="3">However, algorithms, like viruses, can spread bias on a massive scale at a rapid pace.</s>
 <s id="4">Algorithmic bias can also lead to exclusionary experiences and discriminatory practices.</s>
 <s id="5">Let me show you what I mean.</s>
 <p id="p6">
  <s id="6.1">(Video) Joy Buolamwini: Hi, camera.</s>
  <s id="6.2">I've got a face.</s>
 </p>
 <s id="7">Can you see my face?</s>
 <s id="8">No-glasses face?</s>
 <s id="9">You can see her face.</s>
 <s id="10">What about my face?</s>
 <p id="p11">
  <s id="11.1">I've got a mask.</s>
  <s id="11.2">Can you see my mask?</s>
 </p>
 <s id="12">Joy Buolamwini: So how did this happen?</s>
 <s id="13">Why am I sitting in front of a computer in a white mask, trying to be detected by a cheap webcam?</s>
 <s id="14">Well, when I'm not fighting the coded gaze as a poet of code, I'm a graduate student at the MIT Media Lab, and there I have the opportunity to work on all sorts of whimsical projects, including the Aspire Mirror, a project I did so I could project digital masks onto my reflection.</s>
 <s id="15">So in the morning, if I wanted to feel powerful, I could put on a lion.</s>
 <s id="16">If I wanted to be uplifted, I might have a quote.</s>
 <s id="17">So I used generic facial recognition software to build the system, but found it was really hard to test it unless I wore a white mask.</s>
 <s id="18">Unfortunately, I've run into this issue before.</s>
 <s id="19">When I was an undergraduate at Georgia Tech studying computer science, I used to work on social robots, and one of my tasks was to get a robot to play peek-a-boo, a simple turn-taking game where partners cover their face and then uncover it saying, "Peek-a-boo!"</s>
 <s id="20">The problem is, peek-a-boo doesn't really work if I can't see you, and my robot couldn't see me.</s>
 <s id="21">But I borrowed my roommate's face to get the project done, submitted the assignment, and figured, you know what, somebody else will solve this problem.</s>
 <s id="22">Not too long after, I was in Hong Kong for an entrepreneurship competition.</s>
 <s id="23">The organizers decided to take participants on a tour of local start-ups.</s>
 <s id="24">One of the start-ups had a social robot, and they decided to do a demo.</s>
 <s id="25">The demo worked on everybody until it got to me, and you can probably guess it.</s>
 <s id="26">It couldn't detect my face.</s>
 <s id="27">I asked the developers what was going on, and it turned out we had used the same generic facial recognition software.</s>
 <s id="28">Halfway around the world, I learned that algorithmic bias can travel as quickly as it takes to download some files off of the internet.</s>
 <p id="p29">
  <s id="29.1">So what's going on?</s>
  <s id="29.2">Why isn't my face being detected?</s>
 </p>
 <s id="30">Well, we have to look at how we give machines sight.</s>
 <s id="31">Computer vision uses machine learning techniques to do facial recognition.</s>
 <s id="32">So how this works is, you create a training set with examples of faces.</s>
 <p id="p33">
  <s id="33.1">This is a face.</s>
  <s id="33.2">This is a face.</s>
  <s id="33.3">This is not a face.</s>
 </p>
 <s id="34">And over time, you can teach a computer how to recognize other faces.</s>
 <s id="35">However, if the training sets aren't really that diverse, any face that deviates too much from the established norm will be harder to detect, which is what was happening to me.</s>
 <s id="36">But don't worry -- there's some good news.</s>
 <s id="37">Training sets don't just materialize out of nowhere.</s>
 <s id="38">We actually can create them.</s>
 <s id="39">So there's an opportunity to create full-spectrum training sets that reflect a richer portrait of humanity.</s>
 <s id="40">Now you've seen in my examples how social robots was how I found out about exclusion with algorithmic bias.</s>
 <s id="41">But algorithmic bias can also lead to discriminatory practices.</s>
 <s id="42">Across the US, police departments are starting to use facial recognition software in their crime-fighting arsenal.</s>
 <s id="43">Georgetown Law published a report showing that one in two adults in the US -- that's 117 million people -- have their faces in facial recognition networks.</s>
 <s id="44">Police departments can currently look at these networks unregulated, using algorithms that have not been audited for accuracy.</s>
 <s id="45">Yet we know facial recognition is not fail proof, and labeling faces consistently remains a challenge.</s>
 <s id="46">You might have seen this on Facebook.</s>
 <s id="47">My friends and I laugh all the time when we see other people mislabeled in our photos.</s>
 <s id="48">But misidentifying a suspected criminal is no laughing matter, nor is breaching civil liberties.</s>
 <s id="49">Machine learning is being used for facial recognition, but it's also extending beyond the realm of computer vision.</s>
 <s id="50">In her book, "Weapons of Math Destruction," data scientist Cathy O'Neil talks about the rising new WMDs -- widespread, mysterious and destructive algorithms that are increasingly being used to make decisions that impact more aspects of our lives.</s>
 <s id="51">So who gets hired or fired?</s>
 <p id="p52">
  <s id="52.1">Do you get that loan?</s>
  <s id="52.2">Do you get insurance?</s>
 </p>
 <s id="53">Are you admitted into the college you wanted to get into?</s>
 <s id="54">Do you and I pay the same price for the same product purchased on the same platform?</s>
 <s id="55">Law enforcement is also starting to use machine learning for predictive policing.</s>
 <s id="56">Some judges use machine-generated risk scores to determine how long an individual is going to spend in prison.</s>
 <s id="57">So we really have to think about these decisions.</s>
 <s id="58">Are they fair?</s>
 <s id="59">And we've seen that algorithmic bias doesn't necessarily always lead to fair outcomes.</s>
 <s id="60">So what can we do about it?</s>
 <s id="61">Well, we can start thinking about how we create more inclusive code and employ inclusive coding practices.</s>
 <s id="62">It really starts with people.</s>
 <s id="63">So who codes matters.</s>
 <s id="64">Are we creating full-spectrum teams with diverse individuals who can check each other's blind spots?</s>
 <s id="65">On the technical side, how we code matters.</s>
 <s id="66">Are we factoring in fairness as we're developing systems?</s>
 <s id="67">And finally, why we code matters.</s>
 <s id="68">We've used tools of computational creation to unlock immense wealth.</s>
 <s id="69">We now have the opportunity to unlock even greater equality if we make social change a priority and not an afterthought.</s>
 <s id="70">And so these are the three tenets that will make up the "incoding" movement.</s>
 <s id="71">Who codes matters, how we code matters and why we code matters.</s>
 <s id="72">So to go towards incoding, we can start thinking about building platforms that can identify bias by collecting people's experiences like the ones I shared, but also auditing existing software.</s>
 <s id="73">We can also start to create more inclusive training sets.</s>
 <s id="74">Imagine a "Selfies for Inclusion" campaign where you and I can help developers test and create more inclusive training sets.</s>
 <s id="75">And we can also start thinking more conscientiously about the social impact of the technology that we're developing.</s>
 <s id="76">To get the incoding movement started, I've launched the Algorithmic Justice League, where anyone who cares about fairness can help fight the coded gaze.</s>
 <s id="77">On codedgaze.com, you can report bias, request audits, become a tester and join the ongoing conversation, #codedgaze.</s>
 <s id="78">So I invite you to join me in creating a world where technology works for all of us, not just some of us, a world where we value inclusion and center social change.</s>
 <s id="79">Thank you.</s>
 <s id="80">(Applause) But I have one question: Will you join me in the fight?</s>
 <s id="81">(Laughter) (Applause)</s>
</text>
